---
title: Addressing Bias in African AI Models
date: 2025-03-20
author: Kiplangat Korir
excerpt: An exploration of bias in AI models and our initiative to ensure African language technologies work equitably for all users.
---

Last October, I wrote an [article on Medium](https://medium.com/@kiplangatkorir/addressing-bias-in-ai-models-43fc3a01aaa7) about the critical issue of bias in AI models. The response was overwhelming – so many of you shared similar experiences and frustrations. Today, I want to share something exciting: we're taking concrete action on this at MsingiAI.

You see, this isn't just another research project for me. As someone who's been deeply involved in AI development in Africa, I've witnessed firsthand how AI bias affects our communities. Let me share a real example: recently, I was testing a popular language model with Swahili text. The model kept misinterpreting cultural references, missing context, and sometimes even producing harmful stereotypes. It was frustrating, but not surprising.

This is exactly why I've been vocal about AI bias. In my Medium article, I broke down how these biases creep into our systems – from sampling bias to prejudice bias to measurement bias. But here's the thing: knowing about the problem isn't enough. We need to act.

## What We're Actually Doing About It

At MsingiAI, we're not just talking – we're building solutions. Here's our game plan:

1. **Real-World Testing**
   Remember those issues I mentioned with Swahili? We're systematically testing major AI models with African languages. Not in some controlled lab setting, but with real-world usage patterns. We're documenting every bias, every failure, every misunderstanding.

2. **Building Better Tools**
   You know what's crazy? Most "fairness metrics" for AI were developed without considering African languages and contexts. So we're creating our own tools that actually understand our linguistic diversity. Tools that recognize that switching between languages isn't a bug – it's how we naturally communicate.

3. **Community-Driven Solutions**
   This isn't just my project or MsingiAI's project – it belongs to all of us. We're working directly with communities across Africa, learning from their experiences, and incorporating their feedback into our solutions.

## The Real Impact

Let me be straight with you – this isn't just about making AI models more accurate. It's about dignity. It's about representation. It's about ensuring that as AI becomes more integrated into our lives, it serves ALL of us fairly.

Think about it:
- When a loan approval AI system doesn't understand your name format because it's "non-standard" (read: non-Western)
- When a content moderation system flags your perfectly normal Swahili conversation as "suspicious"
- When voice assistants consistently butcher the pronunciation of African names and places

These aren't just technical glitches – they're barriers that keep our communities from fully participating in the digital age.

## Join Us in This Fight

I've been writing and speaking about AI bias for years, but now we're taking real action. If you're as passionate about this as I am, we need your help:

- Are you a developer? Help us build better testing tools
- Are you a linguist? We need your expertise in African languages
- Are you a community leader? Help us understand how AI bias affects your community
- Are you just someone who cares? Share your experiences, spread the word

Remember that Medium article I wrote? That was just the beginning. Now we're building something real, something that matters. And we need you to be part of it.

Reach out to me directly at [information.msingiai@gmail.com](mailto:information.msingiai@gmail.com). Let's make AI work for all of us.

*— Kiplangat Korir*
